{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meRAQbe3ArB7"
      },
      "source": [
        "# 문서 분류(Document Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myxaNrtIl7Z0"
      },
      "source": [
        "## 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85EZuHb-Z9f"
      },
      "source": [
        "* 문서 분류에 필요한 데이터는 `scikit-learn`이 제공하는 20개의 주제를 가지는 뉴스그룹 데이터를 사용\n",
        "* 텍스트는 `CounterVectorizer`를 거쳐 DTM으로 변환\n",
        "* DTM 행렬은 문서에 등장하는 단어들을 빈도 수 별로 표현한 행렬\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AYsGQgxCl-kQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7919, 130107) (7919,) (3395, 130107) (3395,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "news=fetch_20newsgroups()\n",
        "\n",
        "x=news.data\n",
        "y=news.target\n",
        "\n",
        "cv=CountVectorizer()\n",
        "x=cv.fit_transform(x)\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4iRARmcl_EmI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 56979)\t1\n",
            "  (0, 50527)\t1\n",
            "  (0, 111322)\t1\n",
            "  (0, 68532)\t1\n",
            "  (0, 90379)\t1\n",
            "  (0, 118983)\t1\n",
            "  (0, 76032)\t1\n",
            "  (0, 80638)\t1\n",
            "  (0, 68766)\t1\n",
            "  (0, 108252)\t1\n",
            "  (0, 90252)\t1\n",
            "  (0, 76722)\t1\n",
            "  (0, 37423)\t1\n",
            "  (0, 56283)\t1\n",
            "  (0, 72384)\t1\n",
            "  (0, 28146)\t1\n",
            "  (0, 86752)\t1\n",
            "  (0, 50337)\t2\n",
            "  (0, 97049)\t2\n",
            "  (0, 51734)\t1\n",
            "  (0, 41614)\t1\n",
            "  (0, 25399)\t1\n",
            "  (0, 59779)\t1\n",
            "  (0, 51268)\t1\n",
            "  (0, 76377)\t1\n",
            "  (0, 27721)\t1\n",
            "  (0, 123575)\t1\n",
            "  (0, 89884)\t1\n",
            "  (0, 119740)\t1\n",
            "  (0, 26941)\t1\n",
            "  (0, 124425)\t1\n",
            "  (0, 123198)\t2\n",
            "  (0, 113319)\t1\n",
            "  (0, 93245)\t2\n",
            "  (0, 40666)\t1\n",
            "  (0, 122330)\t1\n",
            "  (0, 14141)\t1\n",
            "  (0, 72527)\t3\n",
            "  (0, 43733)\t1\n",
            "  (0, 114421)\t1\n",
            "  (0, 8520)\t1\n",
            "  (0, 95629)\t1\n",
            "  (0, 26954)\t1\n",
            "  (0, 41781)\t1\n"
          ]
        }
      ],
      "source": [
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGM2WbEdAsGL"
      },
      "source": [
        "## scikit-learn을 이용한 문서 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M7g4PrqerCkj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnww8xssA-FL"
      },
      "source": [
        "### 로지스틱 회귀(Logistic Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgUTDK7o9wC6"
      },
      "source": [
        "* 로지스틱 회귀는 이름에 회귀라는 단어가 들어가지만, 가능한 클래스가 2개인 이진 분류를 위한 모델\n",
        "* Logistic Regression은 특성상 다중 분류에는 적합하지 않음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rk3jq9p9DCcv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8689248895434463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\taehwan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR=LogisticRegression()\n",
        "LR.fit(X_train,y_train)\n",
        "pred=LR.predict(X_test)\n",
        "acc=accuracy_score(pred,y_test)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D0CGeJTA-ZH"
      },
      "source": [
        "### 서포트 벡터 머신(Support Vector Machine)\n",
        "* 회귀,분류,이상치 탐지 등에 사용되는 지도학습 방법\n",
        "* 클래스 사이의 경계에 위치한 데이터 포인트를 서포트 벡터(support vector)라고 함\n",
        "* 각 서포트 벡터가 클래스 사이의 결정 경계를 구분하는데 얼마나 중요한지를 학습\n",
        "* 각 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습\n",
        "* 서포트 벡터 까지의 거리와 서포트 벡터의 중요도를 기반으로 예측을 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "cxxK92DGDpyL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8203240058910162\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "SVM=svm.SVC(kernel='linear')\n",
        "SVM.fit(X_train,y_train)\n",
        "pred=SVM.predict(X_test)\n",
        "acc=accuracy_score(pred,y_test)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4g1mEefA-SU"
      },
      "source": [
        "### 나이브 베이즈 분류기(Naive Bayes Classification)\n",
        "* 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
        "* 모든 특성들이 독립임을 가정(naive 가정)\n",
        "* 입력 특성에 따라 3개의 분류기 존재\n",
        "    * 가우시안 나이브 베이즈 분류기\n",
        "    * 베르누이 나이브 베이즈 분류기\n",
        "    * 다항 나이브 베이즈 분류기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcIkL0Bx-AIG"
      },
      "source": [
        "#### DTM을 이용한 Naive Bayes(다항)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ogbxoPS0DMTd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8156111929307805\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB=MultinomialNB()\n",
        "NB.fit(X_train,y_train)\n",
        "pred=NB.predict(X_test)\n",
        "acc=accuracy_score(pred,y_test)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZC7kjWt961H"
      },
      "source": [
        "#### tf-idf를 이용한 정확도 향상"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "c2j7cZc71yiJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8170839469808542\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf=TfidfTransformer()\n",
        "X_train_tf=tfidf.fit_transform(X_train)\n",
        "X_test_tf=tfidf.fit_transform(X_test)\n",
        "\n",
        "NB.fit(X_train_tf,y_train)\n",
        "pred=NB.predict(X_test_tf)\n",
        "acc=accuracy_score(pred,y_test)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPeounJWA-e6"
      },
      "source": [
        "### 결정트리(Decision Tree)\n",
        "* 분류와 회귀에 사용되는 지도 학습 방법\n",
        "* 데이터 특성으로 부터 추론된 결정 규칙을 통해 값을 예측\n",
        "* if-then-else 결정 규칙을 통해 데이터 학습\n",
        "* 트리의 깊이가 깊을 수록 복잡한 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "62wyoby4EEDb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6438880706921944\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT=DecisionTreeClassifier()\n",
        "DT.fit(X_train,y_train)\n",
        "pred=DT.predict(X_test)\n",
        "acc=accuracy_score(pred,y_test)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeEPOjxxA-my"
      },
      "source": [
        "### XGBoost\n",
        "* 트리 기반의 앙상블 기법\n",
        "* 분류에 있어서 다른 알고리즘보다 좋은 예측 성능을 보여줌\n",
        "* XGBoost는 GBM기반이지만, GBM의 단점인 느린 수행 시간과 과적합 규제 부재 등의 문제를 해결\n",
        "* 병렬 CPU 환경에서 빠르게 학습 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "m4TAgLK5ECCi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "0.7237113402061855\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "from xgboost import XGBClassifier\n",
        "xgb=XGBClassifier(n_estimators=30,learning_rate=0.05,max_depth=3)\n",
        "xgb.fit(X_train,y_train)\n",
        "pred=xgb.predict(X_test)\n",
        "acc=accuracy_score(pred,y_test)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1b4PWPBAWwn"
      },
      "source": [
        "### 교차 검증 (Cross Validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd7AexinGlYP"
      },
      "source": [
        "* 일반 검증은 학습 데이터가 테스트 데이터로 사용되지 않음\n",
        "* 교차 검증은 데이터를 n개의 집합으로 나누어 정확도를 계산해 학습 데이터로 사용된 데이터도 테스트 데이터로 사용\n",
        "* 교차 검증을 사용하면 일반 검증보다 모델의 '일반화'가 잘 되어 있는지 평가 가능\n",
        "* 앞서 구성한 나이브 베이즈 모델을 교차 검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZzaiICzaHrI7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.83870968 0.83826779 0.82368537 0.83031374 0.83642794] 0.833480903927519\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores=cross_val_score(NB,x,y,cv=5)\n",
        "print(scores,scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVQBNi5lIn3X"
      },
      "source": [
        "* 교차 검증을 통해 일반 검증보다 좀 더 일반화된 모델 생성 가능\n",
        "* 교차 검증은 일반 검증에 비해 n번 검증을 해 비용이 더 많이 소요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqIU3r_9AZQm"
      },
      "source": [
        "## 정밀도와 재현률 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C0ZPgKLJSvt"
      },
      "source": [
        "* 정밀도(precision)는 양성 클래스(정답)으로 예측한 샘플이 양성 클래스일 확률을 의미\n",
        "* 모델이 얼마나 양성 클래스를 잘 예측하는지를 나타냄\n",
        "* 재현률(recall)은 양성 클래스인 샘플에서 모델이 양성 클래스로 예측한 샘플 비율을 의미하며, 모델이 얼마나 실제 상황을 재현하는지를 나타냄\n",
        "* 정밀도와 재현율의 가중조화평균인 F1-score라는 지표는 정확도에 비해 더 효과적인 모델 분석 지표로 알려져 있음\n",
        "* 직접 계산할 수도 있으나, scikit-learn은 이를 편리하게 계산해주는 함수를 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3hObzsrNuzF"
      },
      "source": [
        "* 다중 클래스 분류 문제에서 정밀도와 재현률을 계산할 때는 클래스간의 지표를 어떻게 합칠지 지정 필요\n",
        "\n",
        "  * None - 클래스간 지표를 합치지 말고 그대로 출력\n",
        "  * micro - 정밀도와 재현률이 같음, 이로 인해 f1-score도 정밀도, 재현률과 동일\n",
        "  * macro - 클래스간 지표를 단순 평균한 값\n",
        "  * weighted - 클래스간 지표를 가중 평균한 값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "98npJWW8J9Px"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8170839469808542 0.8170839469808542 0.8170839469808541\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "\n",
        "precision=precision_score(pred,y_test,average='micro')\n",
        "recall=recall_score(pred,y_test,average='micro')\n",
        "f1=f1_score(pred,y_test,average='micro')\n",
        "\n",
        "print(precision,recall,f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "3JPcMoD0NQi6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8040134958597344 0.8633973042377144 0.8015217239682693\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score,recall_score,f1_score\n",
        "\n",
        "precision=precision_score(pred,y_test,average='macro')\n",
        "recall=recall_score(pred,y_test,average='macro')\n",
        "f1=f1_score(pred,y_test,average='macro')\n",
        "\n",
        "print(precision,recall,f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY3s-EXdArpC"
      },
      "source": [
        "## 그리드 검색을 이용한 파라미터 최적화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0rY-TxKCsOi"
      },
      "source": [
        "* 그리드 검색을 사용하면 분류기에 사용하는 파라미터 최적화 가능\n",
        "* 그리드 검색을 통해 앞서 구성한 나이브 베이즈 모델의 'alpha' 파라미터를 최적화시키는 예제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOkeA7siDdvF"
      },
      "source": [
        "* `estimator`: 사용 모델 객체     \n",
        "* `param_grid`: 사용 객체:지정 파라미터 리스트로 구성된 딕셔너리    \n",
        "* `scoring`: 최적화하고자 하는 성능 지표   \n",
        "* `cv`: 교차 검증 분할 개수      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cCheUO9YBgRi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8897820965842167\n",
            "{'alpha': 0.001}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "GS=GridSearchCV(estimator=NB,param_grid={'alpha':[0.001,0.01,0.1,1.]},scoring='accuracy',cv=10)\n",
        "GS.fit(x,y)\n",
        "\n",
        "print(GS.best_score_)\n",
        "print(GS.best_params_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "_4 문서 분류(Document Classification).ipynb의 사본",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "73d70afa6ea69e9144526a6a5401599dec7b759b7060f809f68e57a7e0099458"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
